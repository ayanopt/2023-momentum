{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPY ETF Financial Data Mining and Feature Engineering\n",
    "\n",
    "## Overview\n",
    "This notebook implements the data extraction and feature engineering pipeline for the SPY ETF algorithmic trading system. It processes raw market data and creates technical indicators used for machine learning model training.\n",
    "\n",
    "### Key Components:\n",
    "- **Data Processing**: Fetches and cleans SPY market data from various sources\n",
    "- **Technical Indicators**: Calculates ATR (Average True Range) and SMA (Standardized Moving Average)\n",
    "- **Profit/Loss Labeling**: Creates target variables for supervised learning\n",
    "- **Cross-Validation**: Implements time-series aware data splitting\n",
    "\n",
    "### Trading Strategy Context:\n",
    "This system focuses on long-only strategies with multiple timeframes (1-3 min, 3-5 min, 5-15 min) to capture different market dynamics.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FinData Class\n",
    "\n",
    "**Purpose**: Central data container and processor for financial market data\n",
    "\n",
    "### Class Structure:\n",
    "- **data**: List of processed DataFrames containing market data with indicators\n",
    "- **Parameters**: Configurable trading and indicator parameters\n",
    "  - `makeATR_k`: Lookback period for ATR calculation (default: 15)\n",
    "  - `p_lambda`: ATR multiplier for profit/loss calculation (default: 10)\n",
    "  - `p_timeout`: Maximum holding period in minutes (default: 180)\n",
    "  - `p_chi`: Profit-to-loss ratio multiplier (default: 1.5)\n",
    "  - `SMA_ks`: List of SMA periods [7, 20, 50]\n",
    "\n",
    "### Methods:\n",
    "- `setParameters()`: Configure trading parameters\n",
    "- `addDataFrame()`: Process raw data and add technical indicators\n",
    "- `ovn()`: Overnight processing for different timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinData:\n",
    "    data = []\n",
    "    makeATR_k = 15\n",
    "    p_lambda = 10\n",
    "    p_timeout =  15*12\n",
    "    p_chi =1.5\n",
    "    SMA_ks = [7,20,50]\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def setParameters(self, makeATR_k_in: int, p_lambda_in: int, p_timeout_in: int,\n",
    "                 p_chi_in: int, SMA_ks_in: list):\n",
    "        self.makeATR_k = makeATR_k_in\n",
    "        self.p_lambda = p_lambda_in\n",
    "        self.p_timeout = p_timeout_in\n",
    "        self.p_chi = p_chi_in\n",
    "        self.SMA_ks = SMA_ks_in\n",
    "        \n",
    "    def addDataFrame(self,df):\n",
    "        # I KNOW this isn't pretty, I swear I'll find a better way. This is a work in progress\n",
    "        df = makeATR(df, self.makeATR_k)\n",
    "        df = PL(df.dropna(),self.p_lambda,self.p_chi,self.p_timeout)\n",
    "        for k in self.SMA_ks:\n",
    "            df = SMA(df,k)\n",
    "        self.data.append((df.dropna()))\n",
    "    def ovn(self,df):\n",
    "        for k in self.SMA_ks:\n",
    "            df = SMA(df,k)\n",
    "        self.data.append(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Average True Range (ATR) Calculation\n",
    "\n",
    "## Purpose\n",
    "ATR measures market volatility and is crucial for dynamic position sizing and risk management. Unlike traditional ATR, this implementation uses price standard deviation for more responsive volatility measurement.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### Traditional OHLC4 Calculation:\n",
    "For any time period i: $OHLC_i = \\frac{Open_i + High_i + Low_i + Close_i}{4}$\n",
    "\n",
    "### Mean Price Calculation:\n",
    "$$\\mu_T = \\frac{\\sum_{i=T-k}^{T}(OHLC_i)}{k}$$\n",
    "\n",
    "### Modified ATR Formula:\n",
    "$$ATR_T = \\sqrt{\\frac{\\sum_{i=T-k}^{T}(OHLC_i - \\mu_T)^2}{k}}$$\n",
    "\n",
    "## Implementation Notes\n",
    "- **Lookback Period (k)**: Default 15 periods, optimized for 1-minute SPY data\n",
    "- **Volatility Measure**: Uses standard deviation instead of true range for smoother signals\n",
    "- **Risk Management**: ATR values directly feed into profit/loss target calculations\n",
    "- **Adaptive Sizing**: Higher ATR = wider stops, lower ATR = tighter stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st\n",
    "import pandas as pd\n",
    "\n",
    "def makeATR(df,k):\n",
    "    means = []\n",
    "    df[\"ATR\"] = df[\"Open\"]\n",
    "    \n",
    "    for i,row in df.iterrows():\n",
    "        # In order to prevent errors with variance calculations, this is incorporated to check if\n",
    "        # the list has less than 2 elts\n",
    "        df.loc[i,\"ATR\"] = pd.NA if len(means) <2 else st.stdev(means)\n",
    "        means.append(row[\"Open\"])\n",
    "        if len(means) >k:\n",
    "            means.pop(0) \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profit and Loss Target System\n",
    "\n",
    "## Overview\n",
    "This system creates binary classification targets (1 = profit, 0 = loss) by simulating forward-looking trades with dynamic profit/loss targets based on market volatility.\n",
    "\n",
    "## Target Calculation Logic\n",
    "For each timestamp, the system determines whether a hypothetical trade would hit profit or loss targets first, creating supervised learning labels.\n",
    "\n",
    "## Key Parameters\n",
    "\n",
    "### 1. ATR Multiplier (λ - Lambda)\n",
    "Controls the sensitivity to market volatility:\n",
    "- **Purpose**: Scales profit/loss targets based on current market conditions\n",
    "- **Example**: If SPY ATR = 0.50 and λ = 10:\n",
    "  - Base volatility adjustment = 10 × 0.50 = $5.00\n",
    "\n",
    "### 2. Profit-to-Loss Ratio (χ - Chi)\n",
    "Asymmetric risk-reward ratio:\n",
    "- **Default**: 1.5 (profit targets 50% wider than loss targets)\n",
    "- **Profit Target**: $Price_T + λ × χ × ATR$\n",
    "- **Loss Target**: $Price_T - λ × ATR$\n",
    "\n",
    "### 3. Timeout Period (t)\n",
    "Maximum holding period before forced exit:\n",
    "- **Purpose**: Prevents indefinite position holding\n",
    "- **Logic**: If neither target hit within t periods, compare exit price to entry\n",
    "- **Classification**: Profit (1) if $Price_{T+t} > Price_T$, Loss (0) otherwise\n",
    "\n",
    "## Risk Management Benefits\n",
    "- **Adaptive Targets**: Wider targets in volatile markets, tighter in calm markets\n",
    "- **Asymmetric Rewards**: Larger profit targets improve risk-adjusted returns\n",
    "- **Time Decay Protection**: Timeout prevents capital tie-up in stagnant positions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Features Created\n",
    "\n",
    "### 1. Binary Classification Target (PL)\n",
    "- **Values**: 0 (loss) or 1 (profit)\n",
    "- **Purpose**: Target variable for classification models (Random Forest, SVM, GLM)\n",
    "- **Usage**: Enables probability-based trading decisions\n",
    "\n",
    "### 2. Continuous Profit/Loss Value (pl_value)\n",
    "- **Purpose**: Actual dollar P&L for regression models and backtesting\n",
    "- **Scale**: Based on 1000-unit position size for standardization\n",
    "- **Usage**: Direct performance measurement and regression target\n",
    "\n",
    "### 3. Statistical Validation\n",
    "- **Win Rate Tracking**: Monitors percentage of profitable trades\n",
    "- **Window Size**: 1-hour rolling window (12 candles for 5-min data)\n",
    "- **Model Calibration**: Ensures predicted probabilities align with actual outcomes\n",
    "- **Reference**: See `strat_book.rmd` for detailed probability analysis\n",
    "\n",
    "### 4. Quality Assurance\n",
    "- **Posterior Probability Validation**: Compares model predictions to realized outcomes\n",
    "- **Temporal Consistency**: Ensures stable win rates across different market regimes\n",
    "- **Overfitting Detection**: Monitors for unrealistic prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "def PL(df, l, chi, t):\n",
    "    df[\"PL\"] = pd.NA\n",
    "    df[\"pl_value\"] = pd.NA\n",
    "    i = 0\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        profit = row[\"Open\"] + l*chi*row[\"ATR\"]\n",
    "        loss = row[\"Open\"] - l*row[\"ATR\"]\n",
    "        \n",
    "        t_copy = t\n",
    "        idx = index\n",
    "        j = i\n",
    "        i+=1\n",
    "        while t_copy >0 and j<len(df):\n",
    "            if idx not in df.index:\n",
    "                break\n",
    "            if df.loc[idx, \"Low\"] <= loss:\n",
    "                df.loc[index, \"PL\"] = 0\n",
    "                df.loc[index,\"pl_value\"] = (loss - row[\"Open\"])*1000\n",
    "                break\n",
    "            elif df.loc[idx, \"High\"] >= profit:\n",
    "                df.loc[index, \"PL\"] = 1\n",
    "                df.loc[index,\"pl_value\"] = (profit - row[\"Open\"])*1000\n",
    "                break\n",
    "            j+=1\n",
    "            idx+=timedelta(minutes=1)\n",
    "            t_copy-=1\n",
    "        if idx not in df.index:\n",
    "            #print(index,idx)\n",
    "            continue\n",
    "        if t_copy == 0 and j<len(df):\n",
    "            profit_loss_indicator = 1 if df.loc[idx, \"Close\"] > row[\"Open\"] else 0\n",
    "            df.loc[index, \"PL\"] = profit_loss_indicator\n",
    "            df.loc[index,\"pl_value\"] = (df.loc[idx, \"Close\"] - row[\"Open\"])*1000        \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Indicators System\n",
    "\n",
    "## Philosophy\n",
    "Technical indicators provide quantitative measures of price momentum, trend strength, and market sentiment. This system uses normalized indicators that adapt to changing market conditions.\n",
    "\n",
    "## Standardized Moving Average (SMA)\n",
    "\n",
    "### Innovation: Price-Relative Normalization\n",
    "Unlike traditional moving averages, this SMA is normalized by current price, making it scale-invariant and comparable across different price levels.\n",
    "\n",
    "### Mathematical Definition\n",
    "$$SMA_k = \\frac{Open_T}{\\frac{1}{k}\\sum_{i=T-k}^{T-1}Close_i}$$\n",
    "\n",
    "Where:\n",
    "- $T$ = current time period\n",
    "- $k$ = lookback period\n",
    "- Values > 1.0 indicate price above historical average (bullish)\n",
    "- Values < 1.0 indicate price below historical average (bearish)\n",
    "\n",
    "### Multi-Timeframe Analysis\n",
    "The system calculates SMA for three periods:\n",
    "- **SMA_7**: Short-term momentum (1 week of 5-min bars)\n",
    "- **SMA_20**: Medium-term trend (1 month of daily closes)\n",
    "- **SMA_50**: Long-term trend (quarterly trend)\n",
    "\n",
    "### Signal Interpretation\n",
    "- **Trend Confirmation**: Multiple SMAs above 1.0 = strong uptrend\n",
    "- **Momentum Divergence**: SMA_7 > SMA_20 > SMA_50 = accelerating uptrend\n",
    "- **Mean Reversion**: Extreme SMA values (>1.05 or <0.95) suggest potential reversal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will create SMA values for the data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMA(df,k):\n",
    "    means = []\n",
    "    colName = \"SMA_k\"+str(k)\n",
    "    df[colName] = [0]*len(df)\n",
    "    for i,row in df.iterrows():\n",
    "        SMA_val = 1 if len(means) <1 else (row[\"Open\"]/st.mean(means))\n",
    "        df.loc[i,colName] = pd.NA if len(means) < 1 else SMA_val\n",
    "        means.append(row[\"Open\"])\n",
    "        if len(means) > k:\n",
    "            means.pop(0)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition and Processing\n",
    "\n",
    "## Data Sources\n",
    "- **Primary**: Local SPY data files (1-minute and 15-minute intervals)\n",
    "- **Backup**: Yahoo Finance API for additional data validation\n",
    "- **Coverage**: Comprehensive historical data for robust backtesting\n",
    "\n",
    "## Data Processing Pipeline\n",
    "\n",
    "### 1. Raw Data Parsing\n",
    "- Converts timestamp format from Unix milliseconds to datetime\n",
    "- Handles OHLCV (Open, High, Low, Close, Volume) data structure\n",
    "- Cleans and validates data integrity\n",
    "\n",
    "### 2. Multiple Timeframe Generation\n",
    "Creates datasets for different trading strategies:\n",
    "- **1-3 minute**: Ultra-short scalping strategies\n",
    "- **3-5 minute**: Short-term momentum capture\n",
    "- **5-15 minute**: Medium-term trend following\n",
    "- **8-60 minute**: Longer-term position strategies\n",
    "\n",
    "### 3. Cross-Validation Framework\n",
    "- **Time-Series Aware**: Maintains temporal order to prevent look-ahead bias\n",
    "- **Walk-Forward Analysis**: Tests strategies on out-of-sample data\n",
    "- **Multiple Folds**: Validates strategy robustness across different market conditions\n",
    "\n",
    "### 4. Output Generation\n",
    "Saves processed datasets as CSV files for R model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "df = pd.DataFrame(columns=[\"Datetime\",\"Open\",\"Close\",\"High\",\"Low\",\"Volume\"])\n",
    "with open (\"../Trade infra/SPY_1m_data.txt\", \"r\") as f:\n",
    "   data = f.read()\n",
    "   data = data.replace(\"{\",\"\")\n",
    "   data = data.replace(\"}\",\"\")\n",
    "   data = data.replace(\"[\",\"\")\n",
    "   data = data.replace(\"]\",\"\")\n",
    "   data = data.replace(\"]\",\"\")\n",
    "   data = data.replace(\" \",\"\")\n",
    "   data = data.replace(\"'\",\"\")\n",
    "   data_list = data.split(\",\")\n",
    "   i = -1\n",
    "   for j,x in enumerate(data_list):\n",
    "       if j%6 == 0:\n",
    "           i+=1\n",
    "       temp = x.split(\":\")\n",
    "       if temp[0] == \"datetime\":\n",
    "           temp= dt.fromtimestamp(int(temp[1])/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "           df.loc[i,temp[0].capitalize()]= dt.strptime(temp,'%Y-%m-%d %H:%M:%S')\n",
    "       else: \n",
    "           df.loc[i,temp[0].capitalize()] = float(temp[1])\n",
    "   df=df.set_index(\"Datetime\")\n",
    "df=df.set_index(\"2\")\n",
    "dfx = df.copy()\n",
    "myData = FinData()\n",
    "myData.addDataFrame(df.copy())\n",
    "myData.data[0].to_csv(\"./train2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "# This is really unprofessional however when I developed it I didn't expect for it to be public\n",
    "mydatax1=FinData()\n",
    "mydatax2=FinData()\n",
    "mydatax3=FinData()\n",
    "mydatax4=FinData()\n",
    "mydatax1.setParameters(15,3,5,1.5,[7,20,50])\n",
    "mydatax2.setParameters(15,5,15,1.5,[7,20,50])\n",
    "mydatax3.setParameters(15,8,60,1.5,[7,20,50])\n",
    "mydatax4.setParameters(15,10,180,1.5,[7,20,50])\n",
    "mydatax1.addDataFrame(dfx.copy())\n",
    "mydatax2.addDataFrame(dfx.copy())\n",
    "mydatax3.addDataFrame(dfx.copy())\n",
    "mydatax4.addDataFrame(dfx.copy())\n",
    "mydatax1.data[0].to_csv(\"./trainX3_5.csv\")\n",
    "mydatax2.data[0].to_csv(\"./trainX5_15.csv\")\n",
    "mydatax3.data[0].to_csv(\"./trainX8_60.csv\")\n",
    "mydatax4.data[0].to_csv(\"./trainX10_180.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in [[1,3]]:\n",
    "    import pandas as pd\n",
    "    from datetime import datetime as dt\n",
    "    df = pd.DataFrame(columns=[\"Datetime\",\"Open\",\"Close\",\"High\",\"Low\",\"Volume\"])\n",
    "    with open (\"../Trade infra/train_txt_data/SPY_1m_data.txt\", \"r\") as f:\n",
    "        data = f.read()\n",
    "        data = data.replace(\"{\",\"\")\n",
    "        data = data.replace(\"}\",\"\")\n",
    "        data = data.replace(\"[\",\"\")\n",
    "        data = data.replace(\"]\",\"\")\n",
    "        data = data.replace(\"]\",\"\")\n",
    "        data = data.replace(\" \",\"\")\n",
    "        data = data.replace(\"'\",\"\")\n",
    "        data_list = data.split(\",\")\n",
    "        i = -1\n",
    "        for j,x in enumerate(data_list):\n",
    "            if j%6 == 0:\n",
    "                i+=1\n",
    "            temp = x.split(\":\")\n",
    "            if temp[0] == \"datetime\":\n",
    "                temp= dt.fromtimestamp(int(temp[1])/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                df.loc[i,temp[0].capitalize()]= dt.strptime(temp,'%Y-%m-%d %H:%M:%S')\n",
    "            else: \n",
    "                df.loc[i,temp[0].capitalize()] = float(temp[1])\n",
    "        df=df.set_index(\"Datetime\")\n",
    "    df=df.set_index(\"2\")\n",
    "    #dfx = df.copy()\n",
    "    myData = FinData()\n",
    "    if len(ix) == 2:\n",
    "        myData.setParameters(15,ix[0],ix[1],1.5,[7,20,50])\n",
    "        myData.addDataFrame(df.copy())\n",
    "        myData.data[0].to_csv(f\"./train{ix[0]}_{ix[1]}.csv\")\n",
    "    else:\n",
    "        myData.addDataFrame(df.copy())\n",
    "        myData.data[0].to_csv(f\"./train2.csv\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 mins SPY ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SMA_k7</th>\n",
       "      <th>SMA_k20</th>\n",
       "      <th>SMA_k50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-30 19:00:00</th>\n",
       "      <td>388.97</td>\n",
       "      <td>388.76</td>\n",
       "      <td>389.07</td>\n",
       "      <td>388.71</td>\n",
       "      <td>4818.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-30 19:15:00</th>\n",
       "      <td>388.75</td>\n",
       "      <td>388.66</td>\n",
       "      <td>388.91</td>\n",
       "      <td>388.41</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>0.999434</td>\n",
       "      <td>0.999434</td>\n",
       "      <td>0.999434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-30 19:30:00</th>\n",
       "      <td>388.71</td>\n",
       "      <td>388.38</td>\n",
       "      <td>388.71</td>\n",
       "      <td>388.28</td>\n",
       "      <td>2925.0</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>0.999614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-30 19:45:00</th>\n",
       "      <td>388.3</td>\n",
       "      <td>388.01</td>\n",
       "      <td>388.3</td>\n",
       "      <td>387.99</td>\n",
       "      <td>6485.0</td>\n",
       "      <td>0.998688</td>\n",
       "      <td>0.998688</td>\n",
       "      <td>0.998688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-30 20:00:00</th>\n",
       "      <td>388.03</td>\n",
       "      <td>388.11</td>\n",
       "      <td>388.14</td>\n",
       "      <td>388.03</td>\n",
       "      <td>930.0</td>\n",
       "      <td>0.998321</td>\n",
       "      <td>0.998321</td>\n",
       "      <td>0.998321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-14 17:45:00</th>\n",
       "      <td>449.25</td>\n",
       "      <td>449.3</td>\n",
       "      <td>449.39</td>\n",
       "      <td>449.25</td>\n",
       "      <td>11676.0</td>\n",
       "      <td>1.000757</td>\n",
       "      <td>1.000118</td>\n",
       "      <td>0.998820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-14 18:00:00</th>\n",
       "      <td>449.27</td>\n",
       "      <td>449.18</td>\n",
       "      <td>449.27</td>\n",
       "      <td>449.18</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>1.000675</td>\n",
       "      <td>1.000227</td>\n",
       "      <td>0.998876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-14 18:15:00</th>\n",
       "      <td>449.16</td>\n",
       "      <td>449.16</td>\n",
       "      <td>449.16</td>\n",
       "      <td>449.16</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.000321</td>\n",
       "      <td>1.000045</td>\n",
       "      <td>0.998639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-14 18:30:00</th>\n",
       "      <td>449.18</td>\n",
       "      <td>449.3</td>\n",
       "      <td>449.3</td>\n",
       "      <td>449.18</td>\n",
       "      <td>566.0</td>\n",
       "      <td>1.000315</td>\n",
       "      <td>1.000206</td>\n",
       "      <td>0.998701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-14 18:45:00</th>\n",
       "      <td>449.25</td>\n",
       "      <td>449.19</td>\n",
       "      <td>449.28</td>\n",
       "      <td>449.15</td>\n",
       "      <td>6017.0</td>\n",
       "      <td>1.000366</td>\n",
       "      <td>1.000409</td>\n",
       "      <td>0.998890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16624 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Open   Close    High     Low   Volume    SMA_k7  \\\n",
       "2                                                                        \n",
       "2022-10-30 19:00:00  388.97  388.76  389.07  388.71   4818.0       NaN   \n",
       "2022-10-30 19:15:00  388.75  388.66  388.91  388.41   2226.0  0.999434   \n",
       "2022-10-30 19:30:00  388.71  388.38  388.71  388.28   2925.0  0.999614   \n",
       "2022-10-30 19:45:00   388.3  388.01   388.3  387.99   6485.0  0.998688   \n",
       "2022-10-30 20:00:00  388.03  388.11  388.14  388.03    930.0  0.998321   \n",
       "...                     ...     ...     ...     ...      ...       ...   \n",
       "2023-07-14 17:45:00  449.25   449.3  449.39  449.25  11676.0  1.000757   \n",
       "2023-07-14 18:00:00  449.27  449.18  449.27  449.18   1549.0  1.000675   \n",
       "2023-07-14 18:15:00  449.16  449.16  449.16  449.16    500.0  1.000321   \n",
       "2023-07-14 18:30:00  449.18   449.3   449.3  449.18    566.0  1.000315   \n",
       "2023-07-14 18:45:00  449.25  449.19  449.28  449.15   6017.0  1.000366   \n",
       "\n",
       "                      SMA_k20   SMA_k50  \n",
       "2                                        \n",
       "2022-10-30 19:00:00       NaN       NaN  \n",
       "2022-10-30 19:15:00  0.999434  0.999434  \n",
       "2022-10-30 19:30:00  0.999614  0.999614  \n",
       "2022-10-30 19:45:00  0.998688  0.998688  \n",
       "2022-10-30 20:00:00  0.998321  0.998321  \n",
       "...                       ...       ...  \n",
       "2023-07-14 17:45:00  1.000118  0.998820  \n",
       "2023-07-14 18:00:00  1.000227  0.998876  \n",
       "2023-07-14 18:15:00  1.000045  0.998639  \n",
       "2023-07-14 18:30:00  1.000206  0.998701  \n",
       "2023-07-14 18:45:00  1.000409  0.998890  \n",
       "\n",
       "[16624 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "df = pd.DataFrame(columns=[\"Datetime\",\"Open\",\"Close\",\"High\",\"Low\",\"Volume\"])\n",
    "with open (\"../Trade infra/SPY_15m_data.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "    data = data.replace(\"{\",\"\")\n",
    "    data = data.replace(\"}\",\"\")\n",
    "    data = data.replace(\"[\",\"\")\n",
    "    data = data.replace(\"]\",\"\")\n",
    "    data = data.replace(\"]\",\"\")\n",
    "    data = data.replace(\" \",\"\")\n",
    "    data = data.replace(\"'\",\"\")\n",
    "    data_list = data.split(\",\")\n",
    "    i = -1\n",
    "    for j,x in enumerate(data_list):\n",
    "        if j%6 == 0:\n",
    "            i+=1\n",
    "        temp = x.split(\":\")\n",
    "        if temp[0] == \"datetime\":\n",
    "            temp= dt.utcfromtimestamp(int(temp[1])/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            df.loc[i,temp[0].capitalize()]= dt.strptime(temp,'%Y-%m-%d %H:%M:%S')\n",
    "        else: \n",
    "            df.loc[i,temp[0].capitalize()] = float(temp[1])\n",
    "    df=df.set_index(\"Datetime\")\n",
    "df=df.set_index(\"2\")\n",
    "myData = FinData()\n",
    "myData.ovn(df)\n",
    "\n",
    "myData.data[0].to_csv(\"train3.csv\")\n",
    "myData.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {}\n",
    "import datetime\n",
    "df2 = pd.DataFrame()\n",
    "#df2[\"diff\"] = pd.NA\n",
    "\n",
    "#sell all at open\n",
    "nrow = 0\n",
    "start = 0\n",
    "for i,row in df.iterrows():\n",
    "    #df.loc[nrow,\"\"]\n",
    "    if (13<i.hour or i.hour>=20) or (i.hour == 13 and i.minute < 30):\n",
    "        continue\n",
    "    elif i.hour == 19 and i.minute == 55:\n",
    "        nrow+=1\n",
    "        start = row[\"Open\"]\n",
    "    elif i.hour == 13 and i.minute == 30:\n",
    "        continue\n",
    "        df2.loc[nrow,\"diff\"] =row[\"Open\"]- start\n",
    "    else:\n",
    "        for xr in df2.columns:\n",
    "            df2.loc[nrow,str(xr)+\"_\"+str(i)] = row[xr]\n",
    "df2\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95a592613a8b3ba5e5d54ff03ce1a6b21e2ec48be25071d242569fe52523772b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
